{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline \nimport plotly.offline as py\npy.init_notebook_mode(connected = True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport warnings\nfrom collections import Counter\nfrom sklearn.feature_selection import mutual_info_classif\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"015fb112da5c2dc13c0bd11477350e6717096651"},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ac321ec96bc8d043c504f5b639f052756ec8230"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"762dab27af4eaef76dfa2593af2f483a0a806444"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3032e1844f98eecec44f065ca6a008d31087f286"},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c15f92777af6838ba0a9b46c9f88f6511f43a78e"},"cell_type":"code","source":"train_copy = train\ntrain_copy = train_copy.replace(-1,np.NaN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29044541b12a3e51194cd50b8c252df4dc998cd6"},"cell_type":"code","source":"import missingno as mis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75a2ddaf6b42f308261eb4db6b501adbf931fd13"},"cell_type":"code","source":"mis.matrix(df = train_copy.iloc[:,2:39], figsize=(20,14), color = (0.62, 0.1, 0.05))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65e328bd3bbd3d2b1e3f2aee9b76ad8e9814b67c"},"cell_type":"code","source":"data = [go.Bar(\n               x= train['target'].value_counts().index.values,\n               y= train['target'].value_counts().values,\n                text = 'Distribution of Target')]\n\nlayout = go.Layout(title = 'Target Value Distribution' )\nfig = go.Figure(data = data, layout = layout)\n\npy.iplot(fig, filename='basic-bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"733f3306ae6e9ae1d594351232f313f2dbc088c2"},"cell_type":"code","source":"Counter(train.dtypes.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8542dd20701d51a7a9d6d07d6287829a7dc2a5e7"},"cell_type":"code","source":"import gc\ngc.enable()\ndel train_copy\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4a1b8c0cdfce7c8126a5fde2b3a22d803aa8677"},"cell_type":"code","source":"train_float = train.select_dtypes(include=['float64'])\ntrain_int = train.select_dtypes(include=['int64'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b94ab1500ece02acdd928d869bdbda47e2d525dc"},"cell_type":"code","source":"colormap = plt.cm.magma\nplt.figure(figsize = (14,10))\nplt.title('Pearson correlation of continuous features', y=1.05, size=15)\nimport seaborn as sns\n\nsns.heatmap(train_float.corr(), linewidth = 0.1, cmap = colormap, annot= True, linecolor = 'white')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92a96b8f28474875cfbe9274ea9347d7ca1e3631"},"cell_type":"code","source":"colormap = plt.cm.magma\nplt.figure(figsize = (14,10))\nplt.title('Pearson correlation of integer type features', y=1.05, size=15)\nimport seaborn as sns\n\nsns.heatmap(train_int.corr(), linewidth = 0.1, cmap = colormap, linecolor = 'white')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9417f4d784351c98d94a8a58d9269b0421371c20"},"cell_type":"code","source":"mf = mutual_info_classif(train_float.values,train.target.values,n_neighbors=3,random_state=17)\nprint(mf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e57269c77131703f0cac61f176762e9347563c1e"},"cell_type":"code","source":"bin_col = [ col for col in train.columns if '_bin' in col  ]\nzero_list = []\none_list = []\nfor col in bin_col :\n    zero_list.append((train[col]==0).sum())\n    one_list.append((train[col]==1).sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f4d0cfd9727bc985f0df3cbae9ccb1750c77793"},"cell_type":"code","source":"trace1 = go.Bar(x = bin_col,\n               y= zero_list,\n               name = 'Zero Count')\ntrace2 = go.Bar(x= bin_col,\n               y= one_list,\n               name = 'One Count')\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(\n   barmode = 'stack',\ntitle = 'Counts of Zero and One in Binary values')\nfig = go.Figure(data = data , layout=layout)\n\npy.iplot(fig, filename= 'stacked-bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2670591817fc52b26f63a3255cff26c0389c9f3"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcc571339dac775d4cbf2a8e2684d150d1a9e726"},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=150, max_depth=8, min_samples_leaf=4, max_features=0.2, n_jobs=-1, random_state=0 )\nrf.fit(train.drop(['id','target'],axis=1), train.target)\nfeatures = train.drop(['id','target'], axis = 1).columns.values\nprint(\"----- Training Done -----\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfb5531db844dba8047b34b2ac85e7f3dcccd243"},"cell_type":"code","source":"# Scatter plot \ntrace = go.Scatter(\n    y = rf.feature_importances_,\n    x = features,\n    mode='markers',\n    marker=dict(\n        sizemode = 'diameter',\n        sizeref = 1,\n        size = 13,\n        #size= rf.feature_importances_,\n        #color = np.random.randn(500), #set color equal to a variable\n        color = rf.feature_importances_,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = features\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Random Forest Feature Importance',\n    hovermode= 'closest',\n     xaxis= dict(\n         ticklen= 5,\n         showgrid=False,\n        zeroline=False,\n        showline=False\n     ),\n    yaxis=dict(\n        title= 'Feature Importance',\n        showgrid=False,\n        zeroline=False,\n        ticklen= 5,\n        gridwidth= 2\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68110c5a5bea8e82ed14c2ed2e22760f14d0dbe1"},"cell_type":"code","source":"x, y = (list(x) for x in zip(*sorted(zip(rf.feature_importances_, features), \n                                                            reverse = False)))\ntrace2 = go.Bar(\n    x=x ,\n    y=y,\n    marker=dict(\n        color=x,\n        colorscale = 'Viridis',\n        reversescale = True\n    ),\n    name='Random Forest Feature importance',\n    orientation='h',\n)\n\nlayout = dict(\n    title='Barplot of Feature importances',\n     width = 900, height = 2000,\n    yaxis=dict(\n        showgrid=False,\n        showline=False,\n        showticklabels=True,\n#         domain=[0, 0.85],\n    ))\n\nfig1 = go.Figure(data=[trace2])\nfig1['layout'].update(layout)\npy.iplot(fig1, filename='plots')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d24461ca224b96f77af14cc115d090209bd4169c"},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e50818cc0c5bc6d067dc68474f711348cd756ced"},"cell_type":"code","source":"gb = GradientBoostingClassifier(n_estimators= 100, max_depth=3, max_features = 0.2, min_samples_leaf=4, random_state=0)\ngb.fit(train.drop(['id','target'],axis=1), train.target)\nfeatures = train.drop(['id','target'],axis=1).columns.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04edbb499beafcbf816fe22d3138404da681d38e"},"cell_type":"code","source":"# Scatter plot \ntrace = go.Scatter(\n    y = gb.feature_importances_,\n    x = features,\n    mode='markers',\n    marker=dict(\n        sizemode = 'diameter',\n        sizeref = 1,\n        size = 13,\n        #size= rf.feature_importances_,\n        #color = np.random.randn(500), #set color equal to a variable\n        color = gb.feature_importances_,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = features\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Gradient Boosting Machine Feature Importance',\n    hovermode= 'closest',\n     xaxis= dict(\n         ticklen= 5,\n         showgrid=False,\n        zeroline=False,\n        showline=False\n     ),\n    yaxis=dict(\n        title= 'Feature Importance',\n        showgrid=False,\n        zeroline=False,\n        ticklen= 5,\n        gridwidth= 2\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b3c2b1cc900b71114546b3f875599ed15266936"},"cell_type":"code","source":"x, y = (list(x) for x in zip(*sorted(zip(gb.feature_importances_, features), \n                                                            reverse = False)))\ntrace2 = go.Bar(\n    x=x ,\n    y=y,\n    marker=dict(\n        color=x,\n        colorscale = 'Viridis',\n        reversescale = True\n    ),\n    name='Gradient Boosting Classifer Feature importance',\n    orientation='h',\n)\n\nlayout = dict(\n    title='Barplot of Feature importances',\n     width = 900, height = 2000,\n    yaxis=dict(\n        showgrid=False,\n        showline=False,\n        showticklabels=True,\n    ))\n\nfig1 = go.Figure(data=[trace2])\nfig1['layout'].update(layout)\npy.iplot(fig1, filename='plots')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7556052f8d06efd6d1f7204003732c811db2fd9e"},"cell_type":"code","source":"def gini(actual, pred, cmpcol = 0, sortcol = 1):\n    assert( len(actual) == len(pred) )\n    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n    totalLosses = all[:,0].sum()\n    giniSum = all[:,0].cumsum().sum() / totalLosses\n    \n    giniSum -= (len(actual) + 1) / 2.\n    return giniSum / len(actual)\n \ndef gini_normalized(a, p):\n    return gini(a, p) / gini(a, a)\n\ndef gini_xgb(preds, dtrain):\n    labels = dtrain.get_label()\n    gini_score = gini_normalized(labels, preds)\n    return 'gini', gini_score\ndef gini_lgb(preds, dtrain):\n    y = list(dtrain.get_label())\n    score = gini_normalized(y, preds)\n    return 'gini', score, True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7035b368aa5b0a56983ce112f90bcad46348606a"},"cell_type":"code","source":"unwanted = train.columns[train.columns.str.startswith('ps_calc_')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2914152428c48e7419b28d367fc4cb3e1018457f"},"cell_type":"code","source":"train = train.drop(unwanted, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b258143cbf75b6e2f924c92f7712e92be084219"},"cell_type":"code","source":"test = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3653ebb220c44c2f6bf2517825fce170f3b68b09"},"cell_type":"code","source":"test = test.drop(unwanted, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe2637e833484c480fafc285616893fccc2ba2a1"},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5289f3b25942f2dcdda704c8854c8dff1b087e2"},"cell_type":"code","source":"params = {\n    'min_child_weight': 10.0,\n    'objective': 'binary:logistic',\n    'max_depth': 7,\n    'max_delta_step': 1.8,\n    'colsample_bytree': 0.4,\n    'subsample': 0.8,\n    'eta': 0.025,\n    'gamma': 0.65,\n    'num_boost_round' : 700\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f959eb8d617c8dee9e898e3323be8a09d82a2c5"},"cell_type":"code","source":"X = train.drop(['id','target'], axis= 1).values\ny = train.target.values\ntest_id = test.id.values\ntest = test.drop(['id'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c85e9b74e90e29f9e3e1522db3fff4dc9c1d05e6"},"cell_type":"code","source":"features = train.drop(['id','target'], axis= 1).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c419f35b20b364ffed230448ed288818b157b22f"},"cell_type":"code","source":"features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c44ce64dcf7f46e5797ea7d0e6f829113763da1c"},"cell_type":"code","source":"sub = pd.DataFrame()\nsub['id'] = test_id\nsub['target'] = np.zeros_like(test_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3463aee66ccd0070dffae211a0e716b640e22492"},"cell_type":"code","source":"import xgboost as xgb\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"604d51a7ea7223490189ebefb54eaea29f588a09"},"cell_type":"code","source":"nrounds=200  # need to change to 2000\nkfold = 2  # need to change to 5\nskf = StratifiedKFold(n_splits=kfold, random_state=0)\nfor i, (train_index, test_index) in enumerate(skf.split(X, y)):\n    print(' xgb kfold: {}  of  {} : '.format(i+1, kfold))\n    X_train, X_valid = X[train_index], X[test_index]\n    y_train, y_valid = y[train_index], y[test_index]\n    d_train = xgb.DMatrix(X_train, y_train) \n    d_valid = xgb.DMatrix(X_valid, y_valid) \n    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n    xgb_model = xgb.train(params, d_train, nrounds, watchlist, early_stopping_rounds=100, \n                          feval=gini_xgb, maximize=True, verbose_eval=100)\n    sub['target'] += xgb_model.predict(xgb.DMatrix(test[features].values), \n                        ntree_limit=xgb_model.best_ntree_limit+50) / (2*kfold)\ngc.collect()\nsub.head(2)\n\n# lgb\nparams = {'metric': 'auc', 'learning_rate' : 0.01, 'max_depth':10, 'max_bin':10,  'objective': 'binary', \n          'feature_fraction': 0.8,'bagging_fraction':0.9,'bagging_freq':10,  'min_data': 500}\n\nskf = StratifiedKFold(n_splits=kfold, random_state=1)\nfor i, (train_index, test_index) in enumerate(skf.split(X, y)):\n    print(' lgb kfold: {}  of  {} : '.format(i+1, kfold))\n    X_train, X_eval = X[train_index], X[test_index]\n    y_train, y_eval = y[train_index], y[test_index]\n    lgb_model = lgb.train(params, lgb.Dataset(X_train, label=y_train), nrounds, \n                  lgb.Dataset(X_eval, label=y_eval), verbose_eval=100, \n                  feval=gini_lgb, early_stopping_rounds=100)\n    sub['target'] += lgb_model.predict(test[features].values, \n                        num_iteration=lgb_model.best_iteration) / (2*kfold)\n    \nsub.to_csv('sub10.csv', index=False, float_format='%.5f') \ngc.collect()\nsub.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6162b9577cc51f98e49044e116029aaa8348a57"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}